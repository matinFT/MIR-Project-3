[{"id": "2981549002", "title": "Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes.", "reference_count": "55", "citation_count": "27", "abstract": "Wide neural networks with random weights and biases are Gaussian processes, as originally observed by Neal (1995) and more recently by Lee et al. (2018) and Matthews et al. (2018) for deep fully-connected networks, as well as by Novak et al. (2019) and Garriga-Alonso et al. (2019) for deep convolutional networks. We show that this Neural Network-Gaussian Process correspondence surprisingly extends to all modern feedforward or recurrent neural networks composed of multilayer perceptron, RNNs (e.g. LSTMs, GRUs), (nD or graph) convolution, pooling, skip connection, attention, batch normalization, and/or layer normalization. More generally, we introduce a language for expressing neural network computations, and our result encompasses all such expressible neural networks. This work serves as a tutorial on the *tensor programs* technique formulated in Yang (2019) and elucidates the Gaussian Process results obtained there. We provide open-source implementations of the Gaussian Process kernels of simple RNN, GRU, transformer, and batchnorm+ReLU network at this http URL.", "date": 2019, "authors": ["Greg Yang"], "related_topics": ["Recurrent neural network", "Artificial neural network", "Multilayer perceptron", "Gaussian process", "Normalization (statistics)", "Transformer (machine learning model)", "Tensor", "Algorithm", "Feed forward", "Computation", "Pooling", "Computer science"], "references": ["2194775991", "2963403868", "1836465849", "2964308564", "2963446712", "1677182931", "2157331557", "2310919327", "2064675550", "1533861849"]}, {"id": "3105081694", "title": "COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images.", "reference_count": "46", "citation_count": "743", "abstract": "The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. A critical step in the fight against COVID-19 is effective screening of infected patients, with one of the key screening approaches being radiology examination using chest radiography. It was found in early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19. Motivated by this and inspired by the open source efforts of the research community, in this study we introduce COVID-Net, a deep convolutional neural network design tailored for the detection of COVID-19 cases from chest X-ray (CXR) images that is open source and available to the general public. To the best of the authors' knowledge, COVID-Net is one of the first open source network designs for COVID-19 detection from CXR images at the time of initial release. We also introduce COVIDx, an open access benchmark dataset that we generated comprising of 13,975 CXR images across 13,870 patient patient cases, with the largest number of publicly available COVID-19 positive cases to the best of the authors' knowledge. Furthermore, we investigate how COVID-Net makes predictions using an explainability method in an attempt to not only gain deeper insights into critical factors associated with COVID cases, which can aid clinicians in improved screening, but also audit COVID-Net in a responsible and transparent manner to validate that it is making decisions based on relevant information from the CXR images. By no means a production-ready solution, the hope is that the open access COVID-Net, along with the description on constructing the open source COVIDx dataset, will be leveraged and build upon by both researchers and citizen data scientists alike to accelerate the development of highly accurate yet practical deep learning solutions for detecting COVID-19 cases and accelerate treatment of those who need it the most.", "date": 2020, "authors": ["Linda Wang", "Zhong Qiu Lin", "Alexander Wong"], "related_topics": ["Deep learning", "Convolutional neural network", "Image processing", "Benchmark (computing)", "Machine learning", "Key (cryptography)", "Computer science", "Radiography", "Artificial intelligence", "Coronavirus disease 2019 (COVID-19)", "Tomography x ray computed", "X ray image"], "references": ["2194775991", "3001118548", "2962835968", "3008827533", "2919115771", "2108598243", "2963446712", "3007497549", "3010604545", "3008985036"]}, {"id": "2950893734", "title": "Self-Attention Generative Adversarial Networks", "reference_count": "51", "citation_count": "1,558", "abstract": "In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN achieves the state-of-the-art results, boosting the best published Inception score from 36.8 to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.", "date": 2018, "authors": ["Han Zhang 1, Ian Goodfellow 1, Dimitris Metaxas 2, Augustus Odena 1"], "related_topics": ["Boosting (machine learning)", "Visualization", "Normalization (statistics)", "Pattern recognition", "Computer science", "Generative grammar", "Adversarial system", "Artificial intelligence", "Self attention"], "references": ["2964121744", "2963403868", "2117539524", "2099471712", "2964308564", "2963073614", "2962793481", "2963684088", "2963373786", "2963470893"]}, {"id": "3119786062", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "reference_count": "49", "citation_count": "315", "abstract": "While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.", "date": 2021, "authors": ["Alexey Dosovitskiy 1, Lucas Beyer 1, Alexander Kolesnikov 1, Dirk Weissenborn 2, Xiaohua Zhai 1, Thomas Unterthiner 1, Mostafa Dehghani 1, Matthias Minderer 1, Georg Heigold 2, Sylvain Gelly 1, Jakob Uszkoreit 1, Neil Houlsby 3"], "related_topics": ["Transformer (machine learning model)", "Contextual image classification", "Computer vision", "Image (mathematics)", "Computer science", "Scale (chemistry)", "Structure (mathematical logic)", "Conjunction (grammar)", "Artificial intelligence", "Self attention"], "references": ["2194775991", "2618530766", "2964121744", "2963341956", "2963403868", "1836465849", "2108598243", "3118608800", "2963091558", "3034978746"]}, {"id": "2145339207", "title": "Human-level control through deep reinforcement learning", "reference_count": "33", "citation_count": "14,862", "abstract": "The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.", "date": 2015, "authors": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei A. Rusu", "Joel Veness", "Marc G. Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K. Fidjeland", "Georg Ostrovski", "Stig Petersen", "Charles Beattie", "Amir Sadik", "Ioannis Antonoglou", "Helen King", "Dharshan Kumaran", "Daan Wierstra", "Shane Legg", "Demis Hassabis"], "related_topics": ["Reinforcement learning", "Q-learning", "Temporal difference learning", "Artificial neural network", "General video game playing", "Set (psychology)", "Sensory processing", "Reinforcement", "Artificial intelligence", "Computer science"], "references": ["2618530766", "2310919327", "2100495367", "2187089797", "1665214252", "2072128103", "2546302380", "2121863487", "2952509347", "1652505363"]}, {"id": "2153579005", "title": "Distributed Representations of Words and Phrases and their Compositionality", "reference_count": "19", "citation_count": "25,996", "abstract": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.", "date": 2013, "authors": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "related_topics": ["Word2vec", "Word embedding", "Word order", "Word (computer architecture)", "Principle of compositionality", "Softmax function", "Syntax", "Distributional semantics", "Simple (philosophy)", "Natural language processing", "Computer science", "Artificial intelligence"], "references": ["1614298861", "2117130368", "2141599568", "2132339004", "2158139315", "1423339008", "1498436455", "1662133657", "1889268436", "2131462252"]}, {"id": "2194775991", "title": "Deep Residual Learning for Image Recognition", "reference_count": "52", "citation_count": "79,410", "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.", "date": 2016, "authors": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "related_topics": ["Deep learning", "Residual", "Convolutional neural network", "Feature learning", "Vanishing gradient problem", "Artificial neural network", "MNIST database", "Object detection", "Test set", "Transfer of learning", "Softmax function", "Pattern recognition", "Machine learning", "Computer vision", "Computer science", "Transformer (machine learning model)", "Artificial intelligence", "Residual neural network"], "references": ["2618530766", "2962835968", "2097117768", "639708223", "1836465849", "2102605133", "2117539524", "1903029394", "2155893237", "1536680647"]}, {"id": "2963403868", "title": "Attention is All You Need", "reference_count": "0", "citation_count": "19,086", "abstract": "The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.", "date": 2017, "authors": ["Ashish Vaswani 1, Noam Shazeer 1, Niki Parmar 2, Jakob Uszkoreit 1, Llion Jones 1, Aidan N. Gomez 1, Lukasz Kaiser 1, Illia Polosukhin 1"], "related_topics": ["Machine translation", "Encoder", "BLEU", "Speech translation", "Artificial neural network", "Transduction (machine learning)", "Byte pair encoding", "Speech recognition", "Computer science", "Transformer (machine learning model)"], "references": ["2963341956", "2963420686", "2965373594", "2970597249", "2963091558", "2923014074", "2911489562"]}, {"id": "1836465849", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "reference_count": "23", "citation_count": "26,211", "abstract": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.", "date": 2015, "authors": ["Sergey Ioffe", "Christian Szegedy"], "related_topics": ["Normalization (statistics)", "Initialization", "Contextual image classification", "Algorithm", "Machine learning", "Computer science", "Artificial intelligence", "Covariate shift"], "references": ["2097117768", "2117539524", "2095705004", "1677182931", "2146502635", "2310919327", "1665214252", "2168231600", "1533861849", "104184427"]}, {"id": "2964308564", "title": "Neural Machine Translation by Jointly Learning to Align and Translate", "reference_count": "25", "citation_count": "17,608", "abstract": "Abstract: Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.", "date": 2014, "authors": ["Dzmitry Bahdanau 1, Kyunghyun Cho 2, Yoshua Bengio 2"], "related_topics": ["Machine translation", "Artificial neural network", "Phrase", "Sentence", "Encoder", "Artificial intelligence", "Bottleneck", "Byte pair encoding", "Computer science", "Closed captioning"], "references": []}]